# speech-to-sign-
The primary aim of the project is to convert speech input to text and later use the text to produce sign languages from given text. Suppose a person speaks “The sky is blue”. Your system will be able to convert his/her audio to text recognizing every word separately. Your computer will also mimic a flow where recently used words are stored in its memory and help it predict the words in the audio input. The next half would be to convert the text obtained to sign language which could be deciphered by people with hearing impairment.


The main aim of our project is to create an application that can translate speech to sign language. Sign Language is one of the most important and widely used forms of communication for people with speaking and hearing impairments. Although many individuals and groups have made an effort to develop systems that read sign language symbols and translate them into text, there are very few instances of text or audio being converted into sign language. The primary goal of this project is to create a translating system made up of numerous modules that accept English audio input and convert that to English text. This text is then parsed to create a structured grammar representation, on which Sign Language grammar rules are applied.
The major portion of this project involves speech-to-text conversion which we are planning to implement using Two Dimensional Convolutional Networks (CNN), Recurrent Neural Networks (RNN), and  Connectionist Temporal Classification (CTC) loss.
